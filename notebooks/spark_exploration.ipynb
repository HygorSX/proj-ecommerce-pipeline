{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Exploração de Dados com PySpark\n",
    "   Este notebook demonstra como usar o PySpark para carregar e processar dados de um pipeline de e-commerce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Importação de Bibliotecas\n",
    "   Importamos as bibliotecas necessárias para criar uma sessão Spark e manipular dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType, BooleanType\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Mapeamento de Tipos\n",
    "   Definimos um dicionário para mapear tipos de dados de strings para tipos Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_mapping = {\n",
    "    \"string\": StringType(),\n",
    "    \"integer\": IntegerType(),\n",
    "    \"double\": DoubleType(),\n",
    "    \"timestamp\": TimestampType(),\n",
    "    \"boolean\": BooleanType()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Função para Carregar Esquema de JSON\n",
    "   Esta função lê um arquivo JSON e retorna um esquema Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_schema_from_json(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        schema_json = json.load(f)\n",
    "    return StructType([\n",
    "        StructField(f[\"name\"], type_mapping[f[\"type\"]], f[\"nullable\"])\n",
    "        for f in schema_json\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Função para Converter Nomes de Colunas para Snake Case\n",
    "   Esta função converte os nomes das colunas de um DataFrame para o formato snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_snake_case(df):\n",
    "    new_columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', col).lower() for col in df.columns]\n",
    "    return df.toDF(*new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Criação da Sessão Spark\n",
    "   Criamos uma sessão Spark para processar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/03 21:02:11 WARN Utils: Your hostname, DESKTOP-542JM0I, resolves to a loopback address: 127.0.1.1; using 172.18.30.52 instead (on interface eth0)\n",
      "25/06/03 21:02:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/03 21:02:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"EcommercePipeline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Informações dos Datasets\n",
    "   Definimos um dicionário com informações sobre os datasets, incluindo caminhos para os arquivos CSV e seus esquemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_info = {\n",
    "        \"customers\": {\n",
    "            \"csv\": \"../data_source/olist_customers_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/customers_schema.json\"\n",
    "        },\n",
    "        \"geolocation\": {\n",
    "            \"csv\": \"../data_source/olist_geolocation_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/geolocation_schema.json\"\n",
    "        },\n",
    "        \"order_items\": {\n",
    "            \"csv\": \"../data_source/olist_order_items_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/order_items_schema.json\"\n",
    "        },\n",
    "        \"order_payments\": {\n",
    "            \"csv\": \"../data_source/olist_order_payments_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/order_payments_schema.json\"\n",
    "        },\n",
    "          \"order_reviews\": {\n",
    "            \"csv\": \"../data_source/olist_order_reviews_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/order_reviews_schema.json\"\n",
    "        },\n",
    "        \"orders\": {\n",
    "            \"csv\": \"../data_source/olist_orders_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/orders_schema.json\"\n",
    "        },\n",
    "        \"product_category_name_translation\": {\n",
    "            \"csv\": \"../data_source/product_category_name_translation.csv\",\n",
    "            \"schema\": \"../config/schemas/product_category_name_translation_schema.json\"\n",
    "        },\n",
    "        \"products\": {\n",
    "            \"csv\": \"../data_source/olist_products_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/products_schema.json\"\n",
    "        },\n",
    "        \"sellers\": {\n",
    "            \"csv\": \"../data_source/olist_sellers_dataset.csv\",\n",
    "            \"schema\": \"../config/schemas/sellers_schema.json\"\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Processamento dos Datasets\n",
    "   Iteramos sobre cada dataset, carregando o esquema e os dados, e aplicamos a função de conversão para snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dataset: customers\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_unique_id: string (nullable = true)\n",
      " |-- customer_zip_code_prefix: integer (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      "\n",
      "Processando dataset: geolocation\n",
      "root\n",
      " |-- geolocation_zip_code_prefix: integer (nullable = true)\n",
      " |-- geolocation_lat: double (nullable = true)\n",
      " |-- geolocation_lng: double (nullable = true)\n",
      " |-- geolocation_city: string (nullable = true)\n",
      " |-- geolocation_state: string (nullable = true)\n",
      "\n",
      "Processando dataset: order_items\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_item_id: integer (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- shipping_limit_date: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- freight_value: double (nullable = true)\n",
      "\n",
      "Processando dataset: order_payments\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- payment_sequential: integer (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- payment_installments: integer (nullable = true)\n",
      " |-- payment_value: double (nullable = true)\n",
      "\n",
      "Processando dataset: order_reviews\n",
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- review_score: integer (nullable = true)\n",
      " |-- review_comment_title: string (nullable = true)\n",
      " |-- review_comment_message: string (nullable = true)\n",
      " |-- review_creation_date: timestamp (nullable = true)\n",
      " |-- review_answer_timestamp: timestamp (nullable = true)\n",
      "\n",
      "Processando dataset: orders\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: timestamp (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- order_delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- order_delivered_customer_date: timestamp (nullable = true)\n",
      " |-- order_estimated_delivery_date: timestamp (nullable = true)\n",
      "\n",
      "Processando dataset: product_category_name_translation\n",
      "root\n",
      " |-- product_category_name: string (nullable = true)\n",
      " |-- product_category_name_english: string (nullable = true)\n",
      "\n",
      "Processando dataset: products\n",
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_category_name: string (nullable = true)\n",
      " |-- product_name_lenght: integer (nullable = true)\n",
      " |-- product_description_lenght: integer (nullable = true)\n",
      " |-- product_photos_qty: integer (nullable = true)\n",
      " |-- product_weight_g: integer (nullable = true)\n",
      " |-- product_length_cm: integer (nullable = true)\n",
      " |-- product_height_cm: integer (nullable = true)\n",
      " |-- product_width_cm: integer (nullable = true)\n",
      "\n",
      "Processando dataset: sellers\n",
      "root\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- seller_zip_code_prefix: integer (nullable = true)\n",
      " |-- seller_city: string (nullable = true)\n",
      " |-- seller_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, info in datasets_info.items():\n",
    "    print(f\"Processando dataset: {name}\")\n",
    "\n",
    "    schema = load_schema_from_json(info[\"schema\"])\n",
    "    df = spark.read.schema(schema).option(\"header\", True).csv(info[\"csv\"])\n",
    "\n",
    "    df_clean = to_snake_case(df)\n",
    "    df.printSchema()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
